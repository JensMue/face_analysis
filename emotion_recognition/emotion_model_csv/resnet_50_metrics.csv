neutral,"{'precision': 0.6091353996737358, 'recall': 0.5938924822394231, 'f1-score': 0.6014173735638354, 'support': 9431}"
happy,"{'precision': 0.8215507411630558, 'recall': 0.6641318124207858, 'f1-score': 0.7345014335775724, 'support': 8679}"
surprise,"{'precision': 0.4719512195121951, 'recall': 0.5826119683853971, 'f1-score': 0.5214754926730673, 'support': 2657}"
sad,"{'precision': 0.34821967410983706, 'recall': 0.500144466917076, 'f1-score': 0.4105787476280835, 'support': 3461}"
anger,"{'precision': 0.4046184738955823, 'recall': 0.5078764965343415, 'f1-score': 0.4504051411008661, 'support': 1587}"
disgust,"{'precision': 0.17896678966789667, 'recall': 0.10221285563751317, 'f1-score': 0.13011401743796108, 'support': 949}"
fear,"{'precision': 0.38934426229508196, 'recall': 0.19957983193277312, 'f1-score': 0.2638888888888889, 'support': 476}"
accuracy,0.5742290748898679
macro avg,"{'precision': 0.46054093718819783, 'recall': 0.4500642734381871, 'f1-score': 0.44462587069575354, 'support': 27240}"
weighted avg,"{'precision': 0.5995394416128779, 'recall': 0.5742290748898679, 'f1-score': 0.5806593573516973, 'support': 27240}"
Balanced Accuracy Score,{'Balanced Accuracy Score': 0.4500642734381871}
